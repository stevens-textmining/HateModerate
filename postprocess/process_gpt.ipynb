{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-13T18:42:06.690589687Z",
     "start_time": "2023-12-13T18:42:06.303790567Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "hate = pd.read_csv(\"all_examples_hate.csv\", sep = \"\\t\")\n",
    "nonhate = pd.read_csv(\"all_examples_nonhate.csv\", sep = \"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "4274f949",
   "metadata": {},
   "outputs": [],
   "source": [
    "hate['label'] = 1\n",
    "nonhate['label'] = 0\n",
    "\n",
    "combined = pd.concat([hate, nonhate])\n",
    "\n",
    "combined_file_path = \"all_examples.csv\"\n",
    "combined.to_csv(combined_file_path, sep=\"\\t\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "3a87221b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "guideline\n",
       "hatecrime victim                                       367\n",
       "violent speech                                         284\n",
       "better worse than                                      255\n",
       "curse profane                                          254\n",
       "contempt self admission intolerance                    242\n",
       "spread virus                                           235\n",
       "attacking intellectual capability                      231\n",
       "harmful stereotype                                     228\n",
       "economic exclusion                                     221\n",
       "less than adequate                                     218\n",
       "criminal                                               212\n",
       "disgust repulsion                                      208\n",
       "curse sexual                                           208\n",
       "explicit exclusion                                     205\n",
       "deviating norm                                         199\n",
       "attacking derogatory term                              199\n",
       "subhumanity                                            198\n",
       "attack concept associated protected characteristics    198\n",
       "insects                                                190\n",
       "contempt despise dislike                               188\n",
       "attacking appearance                                   183\n",
       "curse genitalia                                        174\n",
       "contempt despise hate                                  174\n",
       "feces                                                  174\n",
       "dehumanization animal                                  172\n",
       "sexual predator                                        167\n",
       "attacking hygiene                                      164\n",
       "filth                                                  163\n",
       "disgust vomit                                          159\n",
       "bacteria                                               153\n",
       "change sexual                                          151\n",
       "segregation                                            145\n",
       "deny existence                                         143\n",
       "political exclusion                                    137\n",
       "social exclusion                                       133\n",
       "attacking character trait                              130\n",
       "disease                                                126\n",
       "attacking education                                    123\n",
       "attacking mental health                                111\n",
       "certain objects                                        105\n",
       "contempt shouldnt exist                                103\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "guideline_counts= combined['guideline'].value_counts()\n",
    "guideline_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "191516ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dataset\n",
       "dynahate          5128\n",
       "gpt               1384\n",
       "hatecheck          442\n",
       "manual             270\n",
       "asonam             152\n",
       "toxic span         100\n",
       "hate offensive      91\n",
       "twitter             33\n",
       "FRENK               19\n",
       "ethos               11\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "guideline_counts= combined['dataset'].value_counts()\n",
    "guideline_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a86ee13c",
   "metadata": {},
   "source": [
    "# Replace sheetname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "6a57ca30",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "hate = pd.read_csv(\"all_examples_hate_raw.csv\", sep = \"\\t\")\n",
    "nonhate = pd.read_csv(\"/data/jzheng36/HateModerate/postprocess/all_examples_nonhate_raw.csv\", sep = \"\\t\")\n",
    "\n",
    "nonhate['guideline'] = nonhate['guideline'].replace('contempt self admission intoler', 'contempt self admission intolerance')\n",
    "nonhate['guideline'] = nonhate['guideline'].replace('attack concept associated prote', 'attack concept associated protected characteristics')\n",
    "nonhate['guideline'] = nonhate['guideline'].replace('attacking intellectual capabili', 'attacking intellectual capability')\n",
    "\n",
    "hate['dataset'] = hate['dataset'].replace('comments', 'toxic span')\n",
    "hate['dataset'] = hate['dataset'].replace('data', 'FRENK')\n",
    "hate['dataset'] = hate['dataset'].replace('davidson', 'hate offensive')\n",
    "\n",
    "output_path = \"/data/jzheng36/HateModerate/postprocess/all_examples_nonhate_raw.csv\"\n",
    "nonhate.to_csv(output_path, sep=\"\\t\", index=False)\n",
    "\n",
    "output_path = \"/data/jzheng36/HateModerate/postprocess/all_examples_hate_raw.csv\"\n",
    "hate.to_csv(output_path, sep=\"\\t\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77f03000",
   "metadata": {},
   "source": [
    "# add gpt to test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e209a11f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "test = pd.read_csv(\"/data/jzheng36/HateModerate/fine_tune/datasets/testing/hatemoderate_test.csv\", sep = \"\\t\")\n",
    "gpt = pd.read_csv(\"all_examples_hate.csv.csv\", sep = \"\\t\")\n",
    "\n",
    "gpt = gpt[gpt['dataset'] == 'gpt']\n",
    "\n",
    "columns_to_keep = ['example_id', 'text', 'guideline', 'labels']\n",
    "gpt = gpt[columns_to_keep]\n",
    "\n",
    "test_updated = pd.concat([test, gpt], ignore_index=True)\n",
    "\n",
    "test_updated.to_csv(\"/data/jzheng36/HateModerate/fine_tune/datasets/testing/hatemoderate_test_updated.csv\", sep=\"\\t\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b90443d0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-25T17:32:43.578047328Z",
     "start_time": "2023-11-25T17:32:43.055439542Z"
    }
   },
   "outputs": [],
   "source": [
    "def process_df(df):\n",
    "    # Group by 'guideline' and count the number of rows without 'gpt' in 'dataset'\n",
    "    counts = df[df['dataset'] != 'gpt'].groupby('guideline').size()\n",
    "\n",
    "    # Filter rows\n",
    "    for guideline, count in counts.items():\n",
    "        if count >= 50:\n",
    "            # Remove rows with 'gpt'\n",
    "            df = df[~((df['guideline'] == guideline) & (df['dataset'] == 'gpt'))]\n",
    "        else:\n",
    "            # Reduce the number of rows including 'gpt' to 50\n",
    "            total_to_keep = 50\n",
    "            non_gpt_count = df[(df['guideline'] == guideline) & (df['dataset'] != 'gpt')].shape[0]\n",
    "            gpt_to_keep = total_to_keep - non_gpt_count\n",
    "            # If there are already less than 50 rows, keep them as is\n",
    "            if gpt_to_keep > 0:\n",
    "                # Randomly select gpt rows to keep\n",
    "                gpt_rows = df[(df['guideline'] == guideline) & (df['dataset'] == 'gpt')]\n",
    "                gpt_rows_kept = gpt_rows.sample(min(gpt_to_keep, len(gpt_rows)), random_state=1)\n",
    "                # Keep only the selected gpt rows and all non-gpt rows\n",
    "                df = df[(df['guideline'] != guideline) | (df['dataset'] != 'gpt') | (df.index.isin(gpt_rows_kept.index))]\n",
    "    \n",
    "    return df\n",
    "\n",
    "processed_hate = process_df(hate)\n",
    "processed_hate_file = \"all_examples_hate.csv\"\n",
    "\n",
    "processed_hate.to_csv(processed_hate_file, sep=\"\\t\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b0a1832",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5765e75c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the test dataset\n",
    "test = pd.read_csv(\"/data/jzheng36/HateModerate/fine_tune/datasets/testing/hatemoderate_test.csv\", sep=\"\\t\")\n",
    "\n",
    "# Filter for hate (labels = 1) and non-hate (labels = 0)\n",
    "hate_test = test[test['labels'] == 1]\n",
    "nonhate_test = test[test['labels'] == 0]\n",
    "\n",
    "# Save the filtered datasets to new CSV files\n",
    "hate_test.to_csv(\"/data/jzheng36/hatemoderate/hatemoderate/step2/hatemoderate_test_hate.csv\", sep=\"\\t\", index=False)\n",
    "nonhate_test.to_csv(\"/data/jzheng36/hatemoderate/hatemoderate/step2/hatemoderate_test_nonhate.csv\", sep=\"\\t\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3f6e876e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids_to_remove.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f336d8d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
